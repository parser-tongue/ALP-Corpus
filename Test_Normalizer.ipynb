{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import importlib\n",
    "import normalizerFunctions \n",
    "normalizerFunctions = importlib.reload(normalizerFunctions)\n",
    "from normalizerFunctions import Training_Corpus, Classifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from Normalization_Dataset import Normalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "from Testing_Dataset import Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_test_sentence(batch):\n",
    "    '''Pads to the longest sample'''\n",
    "    f = lambda x: [sample[x] for sample in batch]\n",
    "    words = f(0)\n",
    "    is_heads = f(2)\n",
    "    seqlens = f(-1)\n",
    "    maxlen = np.array(seqlens).max()\n",
    "    f = lambda x, seqlen: [sample[x] + [0] * (seqlen - len(sample[x])) for sample in batch] # 0: <pad>\n",
    "    x = f(1, maxlen)\n",
    "    f = torch.LongTensor\n",
    "    return words, f(x), is_heads, seqlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_normalizations(model, iterable, idx2label):\n",
    "    normalized = []\n",
    "    model.eval()\n",
    "    for batch in iterable:\n",
    "        with torch.no_grad():\n",
    "            b_lines, x, b_is_heads, seqlens = batch\n",
    "            y = torch.zeros_like(x, dtype=torch.long)\n",
    "            _, _, b_predictions = model(x,y) # does not use y value\n",
    "            b_predictions= b_predictions.detach().cpu().numpy()\n",
    "            batch_norms = []\n",
    "            for line, line_preds, is_heads in zip(b_lines, b_predictions, b_is_heads):\n",
    "                line_preds = [pred for head, pred in zip(is_heads, line_preds) if head == 1]\n",
    "                for pred in line_preds:\n",
    "                    try:\n",
    "                        test = idx2label[pred]\n",
    "                    except KeyError:\n",
    "                        idx2label[pred] = '<pad>'\n",
    "                preds = [idx2label[pred] for pred in line_preds]\n",
    "                assert len(preds)==len(line)\n",
    "                batch_norms.append(preds[1:-1])\n",
    "            normalized.append(batch_norms)\n",
    "    return normalized\n",
    "\n",
    "def normalize_song_corpus(model, corpus_texts, idx2label):\n",
    "    corpus_dataset = Testing(corpus_texts)\n",
    "    index = 0\n",
    "    normalized_songs = [] \n",
    "    zipped = []\n",
    "    for song in corpus_texts:\n",
    "        song_len = len(song)\n",
    "        song_subset = data.Subset(corpus_dataset, range(index,index+song_len))\n",
    "        song_iter = DataLoader(dataset=song_subset,\n",
    "                                batch_size=512,\n",
    "                                shuffle=False,\n",
    "                                num_workers=0,\n",
    "                                collate_fn=pad_test_sentence)\n",
    "        normalized_by_classifier = get_normalizations(model, song_iter, idx2label)\n",
    "        normalized_songs.append(normalized_by_classifier)\n",
    "        zipped.append(zip(song,normalized_by_classifier))\n",
    "        index = index + song_len\n",
    "    return normalized_songs, zipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corpus files\n",
    "with open('pickled_archimob.pkl', 'rb') as file:\n",
    "    archimob_corpus = pickle.load(file)\n",
    "with open('pickled_train_corpus.pkl', 'rb') as file:\n",
    "    joined_corpus = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-initialize model\n",
    "model = torch.load('token_classifier_archimob.pt')\n",
    "# model = Classifier(vocab_size=len(alt))\n",
    "model.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(True)\n",
    "    model = nn.DataParallel(model)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group utterances into lists of an arbitrary length so they are the same format as our songs\n",
    "def group_utterances(word_norm_pairs, groupsize=10):\n",
    "    grouped_list = []\n",
    "    sublist = []\n",
    "    for item in word_norm_pairs:\n",
    "        sublist.append(item)\n",
    "        if len(sublist) == groupsize:\n",
    "            grouped_list.append(sublist)\n",
    "            sublist = []\n",
    "    if sublist:\n",
    "        grouped_list.append(sublist)\n",
    "    return grouped_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_utterances =group_utterances(archimob_corpus.word_norm_pairs)\n",
    "utterances_unnormed = [[[word for word, _ in utterance] for utterance in utterances] for utterances in grouped_utterances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "archimob_dataset = Testing(utterances_unnormed)\n",
    "archimob_iter = DataLoader(dataset=archimob_dataset,\n",
    "                            batch_size=8,\n",
    "                            shuffle=False,\n",
    "                            num_workers=0,\n",
    "                            collate_fn=pad_test_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "archimob_normalized_by_classifier = get_normalizations(model, archimob_iter, model.idx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.32864518303735\n",
      "24.67590538397774\n",
      "0.9247072952436618\n"
     ]
    }
   ],
   "source": [
    "# calculate ERR   \n",
    "    \n",
    "def get_model_norms_and_error_rate(list_of_utterances, model_predictions, counts):\n",
    "    normed_utterances = []\n",
    "    total = 0 \n",
    "    hits = 0\n",
    "    words_unnormed = 0\n",
    "    assert len(list_of_utterances)== len(model_predictions)\n",
    "    for u, p in zip(list_of_utterances,model_predictions):\n",
    "        normed_utterance = []\n",
    "        for (word, norm) , pred in zip(u, p):\n",
    "            if word == norm:\n",
    "                words_unnormed += 1\n",
    "            max_key = max(counts[word], key=counts[word].get) \n",
    "            if len(counts[word])>1:       # use the model's prediction unless there is only a single normalization\n",
    "                prediction = pred\n",
    "            else:\n",
    "                prediction = max_key\n",
    "            normed_utterance.append(prediction)\n",
    "            if prediction == norm:\n",
    "                hits += 1\n",
    "            total += 1\n",
    "        normed_utterances.append(normed_utterance)\n",
    "    accuracy = 100*hits/total\n",
    "    unnormed = 100*words_unnormed/total\n",
    "    print(accuracy)\n",
    "    print(unnormed)\n",
    "    Err_Red_rate = (accuracy - unnormed)/(100 - unnormed) \n",
    "    return normed_utterances, Err_Red_rate\n",
    "\n",
    "enhanced_norms, err = get_model_norms_and_error_rate(archimob_corpus.word_norm_pairs, \n",
    "                                                    [n_utterance for group in archimob_normalized_by_classifier for n_utterance in group],\n",
    "                                                    joined_corpus.norm_dict)\n",
    "print(err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
