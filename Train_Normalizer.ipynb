{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "import importlib\n",
    "import normalizerFunctions \n",
    "normalizerFunctions = importlib.reload(normalizerFunctions)\n",
    "from normalizerFunctions import Token_Classifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from Normalization_Dataset import Normalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickled_archimob.pkl', 'rb') as file:\n",
    "    archimob_corpus = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check devixe\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sequence padding \n",
    "def pad(batch):\n",
    "    '''Pads to the longest sample'''\n",
    "    f = lambda x: [sample[x] for sample in batch]\n",
    "    words = f(0)\n",
    "    is_heads = f(2)\n",
    "    labels = f(3)\n",
    "    seqlens = f(-1)\n",
    "    maxlen = np.array(seqlens).max()\n",
    "    f = lambda x, seqlen: [sample[x] + [0] * (seqlen - len(sample[x])) for sample in batch] # 0: <pad>\n",
    "    x = f(1, maxlen)\n",
    "    y = f(-2, maxlen)\n",
    "    f = torch.LongTensor\n",
    "    return words, f(x), is_heads, labels, f(y), seqlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Dataloader(corpus):\n",
    "    labels = [\"<pad>\"] + list(corpus.labels)\n",
    "    label2idx = {label:idx for idx, label in enumerate(labels)}\n",
    "    idx2label = {idx:label for idx, label in enumerate(labels)}\n",
    "    # create training / validation split and load data into batches \n",
    "    train_data, val_data = train_test_split(corpus.word_norm_pairs)\n",
    "    train_dataset = Normalization(train_data, label2idx, corpus.multigrams)\n",
    "    val_dataset = Normalization(val_data,label2idx, corpus.multigrams)\n",
    "\n",
    "    train_iter = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=8,\n",
    "                                shuffle=True,\n",
    "                                num_workers=0,\n",
    "                                collate_fn=pad)\n",
    "    val_iter = data.DataLoader(dataset=val_dataset,\n",
    "                                batch_size=8,\n",
    "                                shuffle=False,\n",
    "                                num_workers=0,\n",
    "                                collate_fn=pad)\n",
    "    print(\"Data loaded\")\n",
    "    return train_iter, val_iter, label2idx, idx2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalizer(corpus,name):\n",
    "    train_iter, val_iter, label2idx,idx2label = get_Dataloader(corpus)\n",
    "    model = Token_Classifier(label2idx,idx2label)\n",
    "    model.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(True)\n",
    "        model = nn.DataParallel(model)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "    epochs = 4\n",
    "    # performance and monitoring metrics \n",
    "    training_stats = []\n",
    "    total_t0 = time.time()\n",
    "    total_steps = len(train_iter) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                                num_training_steps = total_steps)\n",
    "    # Full training loop\n",
    "    for epoch in range(0,epochs):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
    "        print('Training...')\n",
    "        t0 = time.time()\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_iter):\n",
    "            # Progress update every 500 batches.\n",
    "            if step % 500 == 0 and not step == 0:\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "                print('Batch {} of {}.Elapsed: {:}.'.format(step, len(train_iter), elapsed))\n",
    "            words, x, is_heads, labels, y, seqlens = batch\n",
    "            _y = y # for monitoring\n",
    "            optimizer.zero_grad()\n",
    "            logits, y, _ = model(x, y) # logits: (N, L, VOCAB), y: (N, L)\n",
    "            logits = logits.view(-1, logits.shape[-1]) # (N*L, VOCAB)\n",
    "            y = y.view(-1)  # (N*L,)\n",
    "            loss = criterion(logits, y)\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            if step%1000==0: # monitoring\n",
    "                print(\"step: {}, loss: {}\".format(step, loss.item()))\n",
    "        avg_train_loss = total_train_loss / len(train_iter)\n",
    "        training_time = format_time(time.time() - t0)\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        # Validation: \n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "        t0 = time.time()\n",
    "        model.eval()\n",
    "        # total_eval_loss = 0\n",
    "        total = 0\n",
    "        hits = 0\n",
    "        words_unnormed = 0\n",
    "        with open(\"norm_test_\"+name+\".txt\", 'w') as fout: # generates a results file with the word, the true label, and the prediction\n",
    "            for batch in val_iter:\n",
    "                with torch.no_grad():        \n",
    "                    b_utterances, x, b_is_heads, b_labels, y, seqlens = batch\n",
    "                    _, _, b_predictions = model(x, y) # logits: (N, L, VOCAB), y: (N, L)\n",
    "                    b_predictions = b_predictions.detach().cpu().numpy() # pred_ids.cpu().numpy().tolist() alternative?\n",
    "                    assert len(b_utterances)==len(b_labels)== len(b_predictions)                \n",
    "                    for utterance, utterance_labels, utterance_preds, is_heads in zip(b_utterances, b_labels, b_predictions, b_is_heads):\n",
    "                        utterance_preds = [pred for head, pred in zip(is_heads, utterance_preds) if head == 1]\n",
    "                        for pred in utterance_preds:\n",
    "                            try:\n",
    "                                test = idx2label[pred]\n",
    "                            except KeyError:\n",
    "                                idx2label[pred] = '<pad>'\n",
    "                        preds = [idx2label[pred] for pred in utterance_preds]\n",
    "                        words = utterance.split()\n",
    "                        labels = utterance_labels.split()\n",
    "                        assert len(preds)==len(words)== len(labels)\n",
    "                        for w, l, p in zip(words[1:-1], labels[1:-1], preds[1:-1]):\n",
    "                            if w == l:\n",
    "                                words_unnormed += 1\n",
    "                            if l == p:\n",
    "                                hits += 1\n",
    "                            total += 1\n",
    "        accuracy = 100*hits/total\n",
    "        unnormed = 100*words_unnormed/total\n",
    "        print(\"Epoch {} accuracy: \".format(epoch+1),accuracy)\n",
    "        print(unnormed)\n",
    "        Err_Red_rate = (accuracy - unnormed)/(100 - unnormed) # all are percentages\n",
    "        print(Err_Red_rate)\n",
    "        print(\"Epoch {} error reduction rate: \".format(epoch+1),Err_Red_rate)\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                # 'Valid. Loss': avg_val_loss,\n",
    "                #'Validation Time': validation_time,\n",
    "                'Error Reduction': Err_Red_rate,\n",
    "                'Training Time': training_time\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "    torch.save(model, 'token_classifier_'+name+'.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name must be changed on each run to avoid overwriting existing model\n",
    "get_normalizer(archimob_corpus,'archimob_v2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
